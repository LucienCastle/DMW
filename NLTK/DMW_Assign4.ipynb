{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "We meet his boss, Ted Waller, a lover of puzzles. Waller fires Bryson from the Directorate, saying he's lost his touch; Bryson is now told to live as a professor of Byzantine history under the alias of Jonas Barett. After some initial drunkenness and a search for oblivion because his wife, Elena, has left him, he agrees to take the job. He lives under this alias for 5 years and becomes a popular professor, until the Deputy Director of Central Intelligence at the CIA, Harry Dunne, confronts him with a shocking revelation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"train\"\n",
    "files = []\n",
    "# fp = open(path+\"/\"+\"train.txt\",\"r\")\n",
    "for file in os.listdir(path):\n",
    "    try:\n",
    "        fp = open(path+\"/\"+file)\n",
    "        files.append(fp.read())\n",
    "    except:\n",
    "        fp.close()\n",
    "print(len(files))\n",
    "print(files[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'meet', 'boss', ',', 'Ted', 'Waller', ',', 'lover', 'puzzles', '.', 'Waller', 'fires', 'Bryson', 'Directorate', ',', 'saying', \"'s\", 'lost', 'touch', ';', 'Bryson', 'told', 'live', 'professor', 'Byzantine', 'history', 'alias', 'Jonas', 'Barett', '.', 'After', 'initial', 'drunkenness', 'search', 'oblivion', 'wife', ',', 'Elena', ',', 'left', ',', 'agrees', 'take', 'job', '.', 'He', 'lives', 'alias', '5', 'years', 'becomes', 'popular', 'professor', ',', 'Deputy', 'Director', 'Central', 'Intelligence', 'CIA', ',', 'Harry', 'Dunne', ',', 'confronts', 'shocking', 'revelation', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_files = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for file in files:\n",
    "    word_tokens = word_tokenize(file)\n",
    "    filtered_tokens = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_tokens.append(w)\n",
    "#     print(word_tokens)\n",
    "    filtered_files.append(filtered_tokens)\n",
    "print(filtered_files[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'meet', 'boss', ',', 'ted', 'waller', ',', 'lover', 'puzzl', '.', 'waller', 'fire', 'bryson', 'director', ',', 'say', \"'s\", 'lost', 'touch', ';', 'bryson', 'told', 'live', 'professor', 'byzantin', 'histori', 'alia', 'jona', 'barett', '.', 'after', 'initi', 'drunken', 'search', 'oblivion', 'wife', ',', 'elena', ',', 'left', ',', 'agre', 'take', 'job', '.', 'He', 'live', 'alia', '5', 'year', 'becom', 'popular', 'professor', ',', 'deputi', 'director', 'central', 'intellig', 'cia', ',', 'harri', 'dunn', ',', 'confront', 'shock', 'revel', '.']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_files = []\n",
    "for file in filtered_files:\n",
    "    stemmed_tokens = []\n",
    "    for w in file:\n",
    "        stemmed_tokens.append(ps.stem(w))\n",
    "    stemmed_files.append(stemmed_tokens)\n",
    "print(stemmed_files[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vctr = CountVectorizer()\n",
    "# print(files)\n",
    "vctr.fit(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'at': 20, 'another': 13, 'point': 152, 'when': 219, 'he': 89, 'is': 109, 'about': 2, 'to': 200, 'be': 24, 'shot': 175, 'by': 34, 'former': 78, 'enemy': 60, 'saved': 169, 'waller': 212, 'who': 221, 'explains': 71, 'that': 190, 'harry': 86, 'dunne': 57, 'really': 164, 'part': 149, 'of': 139, 'prometheus': 158, 'an': 11, 'organization': 143, 'business': 32, 'executives': 70, 'and': 12, 'powerful': 156, 'politicians': 154, 'around': 16, 'the': 191, 'world': 224, 'members': 132, 'are': 15, 'pushing': 161, 'treaty': 204, 'on': 140, 'surveillance': 183, 'which': 220, 'would': 225, 'allow': 8, 'for': 77, 'international': 108, 'super': 181, 'fbi': 73, 'their': 192, 'own': 147, 'richard': 166, 'lanchester': 116, 'businessman': 33, 'turned': 206, 'politician': 153, 'head': 90, 'implication': 100, 'this': 198, 'because': 25, 'its': 111, 'information': 104, 'companies': 39, 'then': 194, 'able': 1, 'monitor': 134, 'everything': 68, 'went': 217, 'in': 101, 'thereby': 196, 'control': 43, 'it': 110, 'story': 180, 'begins': 28, 'with': 223, 'protagonist': 159, 'under': 207, 'alias': 7, 'technician': 186, 'deep': 48, 'cover': 45, 'stop': 179, 'hezbollah': 93, 'terrorist': 188, 'from': 79, 'overthrowing': 146, 'government': 84, 'tunisia': 205, 'operation': 142, 'appears': 14, 'going': 83, 'well': 216, 'until': 209, 'terrorists': 189, 'discover': 54, 'weapons': 215, 'has': 87, 'supplied': 182, 'them': 193, 'defective': 49, 'before': 27, 'ensuing': 63, 'battle': 23, 'over': 145, 'though': 199, 'abu': 3, 'leader': 119, 'agency': 5, 'manages': 128, 'stab': 178, 'him': 94, 'abdomen': 0, 'helicoptered': 92, 'out': 144, 'we': 214, 'next': 136, 'find': 74, 'entering': 64, 'headquarters': 91, 'directorate': 53, 'learn': 120, 'russian': 168, 'intelligence': 106, 'created': 46, 'gru': 85, 'masterminds': 129, 'essentially': 66, 'penetration': 150, 'american': 10, 'soil': 176, 'learns': 121, 'his': 95, 'boss': 30, 'gennady': 80, 'rosovsky': 167, 'assumed': 19, 'name': 135, 'ted': 187, 'after': 4, 'english': 62, 'poet': 151, 'edmund': 58, 'says': 171, 'bryson': 31, 'entire': 65, 'life': 123, 'including': 102, 'parents': 148, 'death': 47, 'was': 213, 'engineered': 61, 'lead': 118, 'every': 67, 'mission': 133, 'undertaken': 208, 'designed': 51, 'hurt': 99, 'interests': 107, 'horrifies': 97, 'convinced': 44, 'go': 81, 'infiltrates': 103, 'tanker': 185, 'what': 218, 'they': 197, 're': 163, 'doing': 55, 'amassing': 9, 'there': 195, 'meets': 131, 'layla': 117, 'blowing': 29, 'up': 210, 'arsenal': 17, 'continues': 42, 'search': 172, 'however': 98, 'seems': 173, 'everywhere': 69, 'goes': 82, 'attack': 21, 'follows': 76, 'pursues': 160, 'trail': 203, 'contacts': 41, 'colleague': 38, 'jan': 112, 'vansina': 211, 'only': 141, 'have': 88, 'killed': 115, 'eyes': 72, 'meet': 130, 'lover': 127, 'puzzles': 162, 'fires': 75, 'saying': 170, 'lost': 126, 'touch': 202, 'now': 137, 'told': 201, 'live': 124, 'as': 18, 'professor': 157, 'byzantine': 35, 'history': 96, 'jonas': 114, 'barett': 22, 'some': 177, 'initial': 105, 'drunkenness': 56, 'oblivion': 138, 'wife': 222, 'elena': 59, 'left': 122, 'agrees': 6, 'take': 184, 'job': 113, 'lives': 125, 'years': 226, 'becomes': 26, 'popular': 155, 'deputy': 50, 'director': 52, 'central': 36, 'cia': 37, 'confronts': 40, 'shocking': 174, 'revelation': 165}\n"
     ]
    }
   ],
   "source": [
    "print(vctr.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "The Prometheus Deception is a spy fiction thriller novel written in 2000 by Robert Ludlum about an agent in an ultraclandestine agency known only as the Directorate named Nick Bryson, alias Jonas Barett, alias Jonathan Coleridge, alias The Technician, who is thrown into a fight between an organization he knows as Prometheus and his former employers at the Directorate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"test\"\n",
    "test_files = []\n",
    "# fp = open(path+\"/\"+\"train.txt\",\"r\")\n",
    "for file in os.listdir(path):\n",
    "    try:\n",
    "        fp = open(path+\"/\"+file)\n",
    "        test_files.append(fp.read())\n",
    "    except:\n",
    "        fp.close()\n",
    "print(len(test_files))\n",
    "print(test_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newvector = vctr.transform(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      "  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 7 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 1 0 3 0 0 0 3 1 0 0 0 0 0 2 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0\n",
      "  0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(newvector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'at': 20, 'another': 13, 'point': 152, 'when': 219, 'he': 89, 'is': 109, 'about': 2, 'to': 200, 'be': 24, 'shot': 175, 'by': 34, 'former': 78, 'enemy': 60, 'saved': 169, 'waller': 212, 'who': 221, 'explains': 71, 'that': 190, 'harry': 86, 'dunne': 57, 'really': 164, 'part': 149, 'of': 139, 'prometheus': 158, 'an': 11, 'organization': 143, 'business': 32, 'executives': 70, 'and': 12, 'powerful': 156, 'politicians': 154, 'around': 16, 'the': 191, 'world': 224, 'members': 132, 'are': 15, 'pushing': 161, 'treaty': 204, 'on': 140, 'surveillance': 183, 'which': 220, 'would': 225, 'allow': 8, 'for': 77, 'international': 108, 'super': 181, 'fbi': 73, 'their': 192, 'own': 147, 'richard': 166, 'lanchester': 116, 'businessman': 33, 'turned': 206, 'politician': 153, 'head': 90, 'implication': 100, 'this': 198, 'because': 25, 'its': 111, 'information': 104, 'companies': 39, 'then': 194, 'able': 1, 'monitor': 134, 'everything': 68, 'went': 217, 'in': 101, 'thereby': 196, 'control': 43, 'it': 110, 'story': 180, 'begins': 28, 'with': 223, 'protagonist': 159, 'under': 207, 'alias': 7, 'technician': 186, 'deep': 48, 'cover': 45, 'stop': 179, 'hezbollah': 93, 'terrorist': 188, 'from': 79, 'overthrowing': 146, 'government': 84, 'tunisia': 205, 'operation': 142, 'appears': 14, 'going': 83, 'well': 216, 'until': 209, 'terrorists': 189, 'discover': 54, 'weapons': 215, 'has': 87, 'supplied': 182, 'them': 193, 'defective': 49, 'before': 27, 'ensuing': 63, 'battle': 23, 'over': 145, 'though': 199, 'abu': 3, 'leader': 119, 'agency': 5, 'manages': 128, 'stab': 178, 'him': 94, 'abdomen': 0, 'helicoptered': 92, 'out': 144, 'we': 214, 'next': 136, 'find': 74, 'entering': 64, 'headquarters': 91, 'directorate': 53, 'learn': 120, 'russian': 168, 'intelligence': 106, 'created': 46, 'gru': 85, 'masterminds': 129, 'essentially': 66, 'penetration': 150, 'american': 10, 'soil': 176, 'learns': 121, 'his': 95, 'boss': 30, 'gennady': 80, 'rosovsky': 167, 'assumed': 19, 'name': 135, 'ted': 187, 'after': 4, 'english': 62, 'poet': 151, 'edmund': 58, 'says': 171, 'bryson': 31, 'entire': 65, 'life': 123, 'including': 102, 'parents': 148, 'death': 47, 'was': 213, 'engineered': 61, 'lead': 118, 'every': 67, 'mission': 133, 'undertaken': 208, 'designed': 51, 'hurt': 99, 'interests': 107, 'horrifies': 97, 'convinced': 44, 'go': 81, 'infiltrates': 103, 'tanker': 185, 'what': 218, 'they': 197, 're': 163, 'doing': 55, 'amassing': 9, 'there': 195, 'meets': 131, 'layla': 117, 'blowing': 29, 'up': 210, 'arsenal': 17, 'continues': 42, 'search': 172, 'however': 98, 'seems': 173, 'everywhere': 69, 'goes': 82, 'attack': 21, 'follows': 76, 'pursues': 160, 'trail': 203, 'contacts': 41, 'colleague': 38, 'jan': 112, 'vansina': 211, 'only': 141, 'have': 88, 'killed': 115, 'eyes': 72, 'meet': 130, 'lover': 127, 'puzzles': 162, 'fires': 75, 'saying': 170, 'lost': 126, 'touch': 202, 'now': 137, 'told': 201, 'live': 124, 'as': 18, 'professor': 157, 'byzantine': 35, 'history': 96, 'jonas': 114, 'barett': 22, 'some': 177, 'initial': 105, 'drunkenness': 56, 'oblivion': 138, 'wife': 222, 'elena': 59, 'left': 122, 'agrees': 6, 'take': 184, 'job': 113, 'lives': 125, 'years': 226, 'becomes': 26, 'popular': 155, 'deputy': 50, 'director': 52, 'central': 36, 'cia': 37, 'confronts': 40, 'shocking': 174, 'revelation': 165}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.09861229 2.09861229 2.09861229 2.09861229 1.40546511 1.69314718\n",
      " 2.09861229 1.69314718 2.09861229 2.09861229 2.09861229 1.69314718\n",
      " 1.18232156 2.09861229 2.09861229 1.69314718 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 1.69314718 2.09861229 2.09861229 2.09861229\n",
      " 1.40546511 1.69314718 2.09861229 1.69314718 2.09861229 2.09861229\n",
      " 1.69314718 1.40546511 2.09861229 2.09861229 1.69314718 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 1.18232156\n",
      " 2.09861229 2.09861229 2.09861229 1.40546511 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 1.69314718 2.09861229 2.09861229 1.40546511\n",
      " 1.69314718 1.69314718 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 1.69314718 1.40546511 2.09861229 1.\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 1.40546511 1.40546511\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 1.69314718\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 1.69314718 2.09861229\n",
      " 2.09861229 1.         1.69314718 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 1.         1.69314718 2.09861229 1.69314718 1.69314718\n",
      " 1.69314718 2.09861229 2.09861229 2.09861229 2.09861229 1.69314718\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 1.69314718 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 1.69314718 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 1.69314718 1.69314718 2.09861229 1.18232156 1.\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229 2.09861229\n",
      " 1.69314718 2.09861229 1.         2.09861229 2.09861229 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 1.69314718 2.09861229 1.69314718\n",
      " 2.09861229 2.09861229 1.40546511 2.09861229 1.40546511 1.69314718\n",
      " 2.09861229 2.09861229 2.09861229 2.09861229 1.69314718 1.40546511\n",
      " 2.09861229 1.40546511 2.09861229 2.09861229 2.09861229]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.16751461 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09437481 0.         0.         0.         0.         0.\n",
      "  0.16751461 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4054492  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16751461 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.11218649\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13514973 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.39910805 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33502922 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16751461 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13514973 0.         0.         0.55875127\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16751461 0.15964322 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16751461 0.         0.        ]\n",
      " [0.         0.         0.16163659 0.         0.         0.13040738\n",
      "  0.         0.39122215 0.         0.         0.         0.39122215\n",
      "  0.09106324 0.         0.         0.         0.         0.\n",
      "  0.32327318 0.         0.13040738 0.         0.16163659 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10824991 0.         0.         0.13040738 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18212647\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13040738 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.0770207\n",
      "  0.         0.         0.         0.         0.         0.10824991\n",
      "  0.         0.         0.         0.         0.         0.26081477\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1540414  0.         0.         0.         0.\n",
      "  0.16163659 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16163659 0.         0.13040738\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.32327318 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16163659 0.         0.         0.         0.         0.30808281\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.10824991\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "newvector = vectorizer.transform(test_files)\n",
    "print(newvector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"bbc-text.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'] = data['category'].map({'tech' : 1, 'business' : 2, 'sport' : 3, 'entertainment' : 4, 'politics' : 5})\n",
    "x = data['text']\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      category                                               text\n",
      "0            1  tv future in the hands of viewers with home th...\n",
      "1            2  worldcom boss  left books alone  former worldc...\n",
      "2            3  tigers wary of farrell  gamble  leicester say ...\n",
      "3            3  yeading face newcastle in fa cup premiership s...\n",
      "4            4  ocean s twelve raids box office ocean s twelve...\n",
      "...        ...                                                ...\n",
      "2220         2  cars pull down us retail figures us retail sal...\n",
      "2221         5  kilroy unveils immigration policy ex-chatshow ...\n",
      "2222         4  rem announce new glasgow concert us band rem h...\n",
      "2223         5  how political squabbles snowball it s become c...\n",
      "2224         3  souness delight at euro progress boss graeme s...\n",
      "\n",
      "[2225 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       tv future in the hands of viewers with home th...\n",
      "1       worldcom boss  left books alone  former worldc...\n",
      "2       tigers wary of farrell  gamble  leicester say ...\n",
      "3       yeading face newcastle in fa cup premiership s...\n",
      "4       ocean s twelve raids box office ocean s twelve...\n",
      "                              ...                        \n",
      "2220    cars pull down us retail figures us retail sal...\n",
      "2221    kilroy unveils immigration policy ex-chatshow ...\n",
      "2222    rem announce new glasgow concert us band rem h...\n",
      "2223    how political squabbles snowball it s become c...\n",
      "2224    souness delight at euro progress boss graeme s...\n",
      "Name: text, Length: 2225, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       2\n",
      "2       3\n",
      "3       3\n",
      "4       4\n",
      "       ..\n",
      "2220    2\n",
      "2221    5\n",
      "2222    4\n",
      "2223    5\n",
      "2224    3\n",
      "Name: category, Length: 2225, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15474)\t0.042853414666450595\n",
      "  (0, 9771)\t0.05394635995774377\n",
      "  (0, 11969)\t0.03475871711548711\n",
      "  (0, 18841)\t0.04246300218475551\n",
      "  (0, 15189)\t0.03137005689346233\n",
      "  (0, 16946)\t0.03520753765636791\n",
      "  (0, 24964)\t0.03691652953910892\n",
      "  (0, 18744)\t0.03884627662431265\n",
      "  (0, 23104)\t0.06127839797554823\n",
      "  (0, 4315)\t0.02334494124686601\n",
      "  (0, 16834)\t0.04463898003860847\n",
      "  (0, 21473)\t0.03329980397866606\n",
      "  (0, 13090)\t0.046300482947661085\n",
      "  (0, 17720)\t0.03127535911865188\n",
      "  (0, 2125)\t0.02728249738463679\n",
      "  (0, 10042)\t0.04515540880311827\n",
      "  (0, 4907)\t0.022903112291034897\n",
      "  (0, 14974)\t0.03342197228421004\n",
      "  (0, 1165)\t0.03672824159120344\n",
      "  (0, 19446)\t0.05394635995774377\n",
      "  (0, 9876)\t0.04694097417527615\n",
      "  (0, 19159)\t0.04694097417527615\n",
      "  (0, 12229)\t0.04694097417527615\n",
      "  (0, 18747)\t0.04246300218475551\n",
      "  (0, 11493)\t0.06543093289043642\n",
      "  :\t:\n",
      "  (1556, 6290)\t0.10227140171511274\n",
      "  (1556, 15639)\t0.03893599890800166\n",
      "  (1556, 18611)\t0.061219196520664446\n",
      "  (1556, 3951)\t0.05627349477905416\n",
      "  (1556, 24140)\t0.0346627761851796\n",
      "  (1556, 17407)\t0.04042535892480101\n",
      "  (1556, 23916)\t0.04475332860366485\n",
      "  (1556, 20094)\t0.0983686932101894\n",
      "  (1556, 9296)\t0.042031512525548986\n",
      "  (1556, 16362)\t0.13064670144263832\n",
      "  (1556, 6697)\t0.03825439135441232\n",
      "  (1556, 18104)\t0.05390525711923415\n",
      "  (1556, 8697)\t0.04936482858129907\n",
      "  (1556, 15203)\t0.054901533178901396\n",
      "  (1556, 19945)\t0.028420750724846025\n",
      "  (1556, 12565)\t0.0422135696564713\n",
      "  (1556, 15296)\t0.03437001970042754\n",
      "  (1556, 14751)\t0.041675352877462706\n",
      "  (1556, 18280)\t0.053208061574604185\n",
      "  (1556, 8610)\t0.039148136452021316\n",
      "  (1556, 4213)\t0.037115965561544575\n",
      "  (1556, 20526)\t0.038522481296219935\n",
      "  (1556, 5483)\t0.03818827953224387\n",
      "  (1556, 11817)\t0.04986962894897694\n",
      "  (1556, 15782)\t0.044513032617959046\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, shuffle = False)\n",
    "x_train_vec = vectorizer.fit_transform(x_train)\n",
    "print(x_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_vec = vectorizer.transform(x_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968562874251497"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(x_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 25281)\t0.02188773761362324\n",
      "  (0, 25152)\t0.05680178877898791\n",
      "  (0, 24963)\t0.07977779640023369\n",
      "  (0, 24776)\t0.10414474014049412\n",
      "  (0, 24761)\t0.048577708604237796\n",
      "  (0, 24617)\t0.07477084919627018\n",
      "  (0, 24611)\t0.10414474014049412\n",
      "  (0, 24344)\t0.05858788620347759\n",
      "  (0, 23403)\t0.08369011442891092\n",
      "  (0, 23356)\t0.0673167461885561\n",
      "  (0, 23147)\t0.07674316677820198\n",
      "  (0, 23130)\t0.03123411412146515\n",
      "  (0, 22942)\t0.06410198876444624\n",
      "  (0, 22580)\t0.11237635132934709\n",
      "  (0, 22566)\t0.04333291088776551\n",
      "  (0, 22233)\t0.105674531005893\n",
      "  (0, 21559)\t0.05503824167392931\n",
      "  (0, 21431)\t0.06522038168908899\n",
      "  (0, 21396)\t0.06687082262476148\n",
      "  (0, 20336)\t0.04758621660261879\n",
      "  (0, 20094)\t0.03655801148068148\n",
      "  (0, 19945)\t0.015843548857588412\n",
      "  (0, 19572)\t0.11044654212403528\n",
      "  (0, 19523)\t0.039794822923679044\n",
      "  (0, 18913)\t0.06926283899066549\n",
      "  :\t:\n",
      "  (667, 9162)\t0.07719861145972674\n",
      "  (667, 8606)\t0.08310613645607776\n",
      "  (667, 8313)\t0.04886484408763641\n",
      "  (667, 7944)\t0.09005694501080687\n",
      "  (667, 7941)\t0.1192940541868331\n",
      "  (667, 7172)\t0.1494105779392196\n",
      "  (667, 6841)\t0.13453947066039829\n",
      "  (667, 6697)\t0.05817897803742704\n",
      "  (667, 6538)\t0.09757858795995346\n",
      "  (667, 6401)\t0.13647083205176813\n",
      "  (667, 5233)\t0.06772246203426771\n",
      "  (667, 3738)\t0.07005556642772562\n",
      "  (667, 3443)\t0.07507622461549082\n",
      "  (667, 3118)\t0.0855832311252349\n",
      "  (667, 3116)\t0.06894219309263003\n",
      "  (667, 3111)\t0.12506332123493927\n",
      "  (667, 2876)\t0.08058079558534784\n",
      "  (667, 2579)\t0.09447962542802174\n",
      "  (667, 1782)\t0.07610708169977587\n",
      "  (667, 1679)\t0.14206111360954488\n",
      "  (667, 1583)\t0.0823488617581734\n",
      "  (667, 1492)\t0.04349766760530312\n",
      "  (667, 398)\t0.07806158817608834\n",
      "  (667, 206)\t0.07103731158850717\n",
      "  (667, 108)\t0.06172317763871654\n"
     ]
    }
   ],
   "source": [
    "prediction = nb.predict(x_test_vec)\n",
    "print(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668,)\n",
      "(668,)\n"
     ]
    }
   ],
   "source": [
    "print(prediction.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 2, 1, 4, 2, 1, 3, 1, 4, 4, 5, 5, 3, 2, 2, 1, 4, 3, 5, 2,\n",
       "       1, 4, 5, 3, 4, 5, 5, 1, 3, 5, 2, 5, 4, 1, 3, 5, 4, 4, 2, 3, 1, 1,\n",
       "       3, 4, 1, 5, 1, 3, 5, 5, 3, 4, 3, 5, 3, 1, 4, 3, 4, 2, 2, 4, 4, 4,\n",
       "       1, 3, 2, 2, 5, 5, 2, 5, 4, 3, 3, 1, 5, 3, 2, 3, 2, 1, 3, 3, 2, 4,\n",
       "       3, 3, 1, 3, 2, 5, 2, 4, 1, 4, 5, 2, 4, 5, 4, 5, 5, 2, 3, 3, 3, 1,\n",
       "       1, 3, 5, 4, 1, 3, 4, 2, 4, 5, 2, 3, 1, 2, 3, 5, 2, 4, 4, 4, 5, 4,\n",
       "       5, 4, 3, 4, 3, 5, 5, 2, 5, 1, 3, 1, 3, 2, 5, 1, 4, 4, 5, 4, 5, 3,\n",
       "       3, 5, 2, 1, 3, 5, 5, 4, 3, 5, 5, 2, 1, 1, 2, 1, 3, 3, 2, 5, 2, 1,\n",
       "       3, 1, 5, 4, 3, 2, 3, 4, 1, 1, 3, 5, 3, 2, 3, 2, 3, 3, 4, 4, 2, 1,\n",
       "       1, 2, 1, 2, 2, 3, 3, 5, 3, 1, 3, 1, 3, 3, 2, 2, 1, 3, 2, 1, 1, 5,\n",
       "       3, 2, 4, 4, 1, 5, 3, 3, 1, 2, 1, 4, 4, 5, 5, 2, 4, 3, 4, 4, 2, 3,\n",
       "       5, 1, 2, 3, 4, 1, 5, 5, 3, 3, 2, 2, 2, 2, 2, 4, 2, 5, 5, 1, 1, 4,\n",
       "       5, 4, 2, 5, 3, 3, 2, 1, 2, 1, 3, 2, 2, 5, 3, 3, 5, 5, 4, 4, 5, 2,\n",
       "       5, 5, 2, 1, 5, 5, 5, 5, 5, 4, 4, 1, 5, 3, 5, 3, 1, 3, 3, 3, 4, 1,\n",
       "       4, 1, 3, 1, 3, 3, 4, 4, 2, 4, 4, 5, 2, 3, 1, 1, 5, 2, 3, 2, 4, 3,\n",
       "       5, 4, 3, 3, 2, 5, 1, 1, 2, 2, 3, 5, 4, 3, 3, 5, 4, 1, 3, 4, 2, 5,\n",
       "       3, 5, 1, 4, 3, 5, 2, 4, 5, 4, 5, 3, 5, 2, 2, 5, 2, 1, 3, 2, 4, 2,\n",
       "       3, 3, 4, 1, 5, 1, 5, 5, 3, 3, 3, 2, 1, 4, 2, 3, 2, 3, 2, 1, 2, 2,\n",
       "       2, 2, 3, 3, 3, 2, 2, 4, 2, 2, 2, 3, 3, 3, 1, 2, 3, 3, 3, 2, 4, 1,\n",
       "       1, 1, 5, 2, 2, 1, 2, 1, 3, 3, 5, 5, 5, 3, 3, 5, 5, 1, 2, 3, 3, 3,\n",
       "       3, 2, 3, 2, 2, 2, 2, 3, 5, 3, 1, 1, 3, 1, 2, 4, 2, 3, 2, 1, 1, 5,\n",
       "       4, 2, 4, 2, 1, 5, 4, 5, 4, 4, 1, 2, 1, 1, 2, 5, 3, 4, 2, 5, 4, 2,\n",
       "       1, 3, 1, 5, 3, 5, 2, 5, 5, 2, 2, 2, 1, 5, 2, 5, 2, 4, 5, 3, 5, 5,\n",
       "       3, 4, 1, 1, 2, 1, 3, 2, 2, 5, 3, 1, 1, 1, 3, 4, 3, 5, 2, 5, 5, 4,\n",
       "       1, 2, 1, 3, 4, 4, 3, 2, 4, 1, 1, 3, 4, 2, 5, 5, 5, 1, 1, 2, 5, 2,\n",
       "       5, 5, 4, 3, 1, 2, 1, 4, 1, 1, 3, 5, 3, 3, 5, 4, 4, 2, 5, 5, 3, 2,\n",
       "       2, 1, 2, 1, 1, 3, 2, 5, 3, 2, 2, 3, 1, 3, 1, 4, 3, 3, 4, 2, 1, 3,\n",
       "       3, 5, 1, 2, 5, 3, 3, 5, 4, 1, 1, 1, 2, 3, 4, 4, 1, 2, 5, 1, 3, 3,\n",
       "       1, 1, 5, 2, 3, 4, 4, 3, 4, 1, 1, 2, 2, 2, 3, 3, 1, 3, 2, 1, 2, 2,\n",
       "       3, 2, 5, 2, 2, 1, 2, 1, 5, 1, 4, 5, 1, 4, 3, 5, 4, 2, 1, 2, 1, 4,\n",
       "       1, 3, 2, 2, 5, 4, 5, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 2 1 4 2 1 2 1 4 4 5 5 3 2 2 1 4 3 5 2 1 4 5 3 4 5 5 1 3 5 2 5 4 5 3\n",
      " 5 2 4 2 3 1 1 3 4 1 5 1 3 5 5 3 4 3 5 3 1 4 3 5 2 2 4 4 2 1 3 2 2 5 5 2 5\n",
      " 4 3 3 1 5 3 2 3 2 1 3 3 2 4 3 3 1 3 2 5 2 4 1 4 5 2 4 5 4 5 5 2 3 3 3 1 1\n",
      " 3 5 4 1 3 4 2 4 2 2 3 1 2 3 5 2 4 4 4 5 4 5 4 3 4 3 5 5 2 5 1 3 1 3 5 5 1\n",
      " 4 4 5 4 5 3 3 5 2 1 3 5 5 4 3 5 5 2 1 3 2 1 3 3 2 5 5 1 3 1 5 4 3 2 3 4 1\n",
      " 1 3 5 3 2 3 2 3 3 4 4 2 1 1 2 1 2 2 3 3 5 3 1 3 1 3 3 2 2 1 3 2 1 1 5 3 2\n",
      " 4 4 1 5 3 3 1 2 1 5 4 5 5 2 4 3 4 4 2 3 5 1 2 3 4 1 5 5 3 3 5 2 2 2 2 4 2\n",
      " 5 5 1 1 4 5 4 2 5 3 3 2 1 2 1 3 2 2 5 3 3 5 5 4 4 5 2 5 5 2 1 5 5 5 5 5 4\n",
      " 4 1 5 3 5 3 1 3 3 3 4 1 4 1 3 1 3 3 4 4 2 4 4 5 2 3 1 1 5 2 3 2 4 3 5 4 3\n",
      " 3 2 5 1 1 2 2 3 5 4 3 3 5 4 1 3 4 2 5 3 5 1 4 3 5 2 4 5 4 5 3 5 2 2 5 2 1\n",
      " 3 2 4 2 3 3 4 1 5 1 5 5 3 3 3 2 1 4 2 3 2 3 2 1 2 2 2 2 3 3 3 2 2 4 2 2 2\n",
      " 3 3 3 1 1 3 3 3 2 4 1 1 1 5 2 2 1 2 1 3 3 5 5 5 3 3 5 5 1 2 3 3 3 3 2 3 2\n",
      " 2 2 2 3 5 3 1 1 3 1 2 4 2 3 2 1 1 5 4 2 4 2 1 5 4 5 4 4 1 2 1 1 2 5 3 4 2\n",
      " 5 4 2 1 3 1 5 3 5 2 5 5 2 2 2 1 5 2 5 2 4 5 3 5 5 3 4 1 1 2 1 3 1 2 2 3 1\n",
      " 1 1 3 4 3 5 2 5 5 4 1 2 1 3 4 4 3 2 4 1 1 3 4 2 5 5 5 1 1 2 5 2 1 5 4 3 1\n",
      " 2 1 4 1 1 3 5 3 3 5 4 4 2 5 5 3 2 2 1 2 1 1 3 2 5 3 2 2 3 1 3 1 4 3 3 4 2\n",
      " 1 3 3 5 1 2 5 3 3 5 2 1 1 1 2 3 4 2 1 2 5 1 3 3 1 1 5 2 3 4 5 3 2 1 1 2 2\n",
      " 2 3 3 1 3 2 1 2 2 3 2 5 2 2 1 5 1 5 2 4 5 1 4 3 5 4 2 1 2 1 4 1 3 2 2 5 4\n",
      " 5 3]\n",
      "Precision :  0.9700399350954123\n",
      "Recall :  0.9662125344780176\n",
      "F1 :  0.967747214199196\n"
     ]
    }
   ],
   "source": [
    "print(prediction)\n",
    "print('Precision : ', precision_score(y_test, prediction, average = 'macro'))\n",
    "print('Recall : ', recall_score(y_test, prediction, average = 'macro'))\n",
    "print('F1 : ', f1_score(y_test, prediction, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['The Chicago Bears great was known for his effortless, slicing runs. Revealing his dementia diagnosis years after his retirement showed the toll of those dazzling performances.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text = vectorizer.transform(text)\n",
    "nb.predict(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
